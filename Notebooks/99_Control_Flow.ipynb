{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tensorboard_graph(path):\n",
    "    \"\"\"Helper to export graph data to be explored in `tensorboard`\"\"\"\n",
    "    tb_dir = os.path.join('tbout', path)\n",
    "    print('Exporting TensorBoard graph to {}'.format(tb_dir))\n",
    "    tf.summary.FileWriter(tb_dir, graph=tf.get_default_graph()).close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control dependencies\n",
    "\n",
    "### Race conditions: a contrived (but demonstrative) example\n",
    "\n",
    "In the below code, notice that both `a` and `b` try to set the value of the `Variable`, `var`. Because there is no implicit dependency between `a` and `b`, they can run in either order each time a `Session` runs them. This causes unstable results, as illustrated with output printed to console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 16, 40, 80, 164, 332, 672, 1352, 2712, 5432]\n",
      "[0, 8, 24, 56, 112, 232, 472, 952, 1912, 3832]\n",
      "[4, 16, 36, 80, 168, 344, 696, 1400, 2808, 5624]\n",
      "[4, 16, 40, 88, 184, 376, 760, 1528, 3064, 6136]\n",
      "[8, 24, 56, 120, 248, 504, 1016, 2040, 4088, 8184]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Our mutable state\n",
    "var = tf.Variable(0)\n",
    "a = tf.assign(var, 2 * var)\n",
    "b = tf.assign_add(var, 2)\n",
    "c = a + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Print the value of c over multiple iterations to show non-determinism\n",
    "for _ in range(5):\n",
    "    with tf.Session() as sess:\n",
    "        vals = []\n",
    "        sess.run(init)\n",
    "        for _ in range(10):\n",
    "            val = sess.run(c)\n",
    "            vals.append(val)\n",
    "        print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there is no implicit dependency, we can force an _explicit_ dependency by using [`tf.control_dependencies()`](https://www.tensorflow.org/api_docs/python/tf/control_dependencies). Below, we use it to add `a` as a dependency to `b`, forcing `b` to wait until `a` has finished before running. Because of this, our execution order, and thus our output, is now completely deterministic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 12, 28, 60, 124, 252, 508, 1020, 2044, 4092]\n",
      "[4, 12, 28, 60, 124, 252, 508, 1020, 2044, 4092]\n",
      "[4, 12, 28, 60, 124, 252, 508, 1020, 2044, 4092]\n",
      "[4, 12, 28, 60, 124, 252, 508, 1020, 2044, 4092]\n",
      "[4, 12, 28, 60, 124, 252, 508, 1020, 2044, 4092]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Our mutable state\n",
    "var = tf.Variable(0)\n",
    "a = tf.assign(var, 2 * var)\n",
    "# Force b to wait for a\n",
    "with tf.control_dependencies([a]):\n",
    "    b = tf.assign_add(var, 2)\n",
    "c = a + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Each run will now be identical\n",
    "for _ in range(5):\n",
    "    with tf.Session() as sess:\n",
    "        vals = []\n",
    "        sess.run(init)\n",
    "        for _ in range(10):\n",
    "            val = sess.run(c)\n",
    "            vals.append(val)\n",
    "        print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfering parameters from one set of variables to another\n",
    "\n",
    "Example: Deep Q-Network, need to send \"online\" parameters to the \"target\" parameters periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to create dummy graph with many value to be transferred from one Variable to another.\n",
    "def create_var_updates_and_init():\n",
    "    tf.reset_default_graph()\n",
    "    print('Creating variables...')\n",
    "    # Create dummy lists of variables for example\n",
    "    master_vars = [tf.Variable(tf.random_normal([100, 100])) for i in range(100)]\n",
    "    replica_vars = [tf.Variable(tf.random_normal([100, 100])) for i in range(100)]\n",
    "    # Create assign ops for each variable\n",
    "    update_ops = []\n",
    "    for i, var in enumerate(replica_vars):\n",
    "        master_var = master_vars[i]\n",
    "        update_ops.append(var.assign(master_var))\n",
    "    # initalization operation\n",
    "    init = tf.global_variables_initializer()\n",
    "    print('Done.')\n",
    "    return update_ops, init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should we run all of the `assign` ops? I've seen things like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variables...\n",
      "Done.\n",
      "Updating Variables...\n",
      "Done.\n",
      "Time elapsed: 0.7024047374725342 seconds\n"
     ]
    }
   ],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Run each update in a separate Session.run() call\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    print('Updating Variables...')\n",
    "    for update in update_ops:\n",
    "        sess.run(update)\n",
    "    end_t = time.time()\n",
    "    print('Done.')\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variables...\n",
      "Done.\n",
      "Updating Variables...\n",
      "Done.\n",
      "Time elapsed: 0.0600435733795166 seconds\n"
     ]
    }
   ],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Create one \"master\" operation which forces all update ops to execute\n",
    "with tf.control_dependencies(update_ops):\n",
    "    assign_all = tf.no_op()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('Updating Variables...')\n",
    "    start_t = time.time()\n",
    "    sess.run(assign_all)\n",
    "    end_t = time.time()\n",
    "    print('Done.')\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.group`\n",
    "\n",
    "The syntax can be made cleaner by using the `tf.group` operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variables...\n",
      "Done.\n",
      "Time elapsed: 0.05835080146789551 seconds\n"
     ]
    }
   ],
   "source": [
    "update_ops, init = create_var_updates_and_init()\n",
    "# Create one \"master\" operation which forces all update ops to execute\n",
    "assign_all = tf.group(*update_ops)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    sess.run(assign_all)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a grouping operation is cleaner, faster, more idiomatic. Compared to the `tf.control_dependencies()` version above, `tf.group()` provides some additional functionality under-the-hood, making sure that operations are grouped according to their device. [Check out the implementation here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py#L2784-L2846)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.tuple`\n",
    "\n",
    "If you want to synchronize multiple parallel operations, [`tf.tuple()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/tuple) is an easy solution. You simply pass in a list of tensors, and `tf.tuple()` prevents future operations from using those tensors until they have all been computed.\n",
    "\n",
    "_Note: TensorFlow operations automatically wait for all dependencies to finish before executing. Use `tf.tuple` for situations where you need to explicitly provide synchronization._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matmul(dims):\n",
    "    return tf.matmul(tf.random_normal([dims, dims]), tf.random_normal([dims, dims]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = make_matmul(100)\n",
    "tensor_b = make_matmul(1000)\n",
    "tensor_c = make_matmul(10000)\n",
    "sync_a, sync_b, sync_c = tf.tuple([tensor_a, tensor_b, tensor_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.cond`\n",
    "\n",
    "`tf.cond` is basically an `if/else` statement. You provide a boolean predicate and two functions which return tensors. One will run if the predicate is `True`, the other if it is `False`. Here's a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "pred = tf.placeholder(tf.bool)\n",
    "def run_if_true():\n",
    "    return tf.add(3, 3)\n",
    "def run_if_false():\n",
    "    return tf.square(3)\n",
    "out = tf.cond(pred, run_if_true, run_if_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice: True\tResult: 6\n"
     ]
    }
   ],
   "source": [
    "# We can run this multiple times and see the result from randomly selecting a true/false input\n",
    "with tf.Session() as sess:\n",
    "    choice = np.random.choice([True, False])\n",
    "    feed_dict = {pred: choice}\n",
    "    res = sess.run(out, feed_dict)\n",
    "    print('Choice: {}\\tResult: {}'.format(choice, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple functions, we can use lambdas instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "pred = tf.placeholder(tf.bool)\n",
    "out = tf.cond(pred, lambda: tf.add(3, 3), lambda: tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic `tf.case` example\n",
    "\n",
    "Try adjusting the `feed_dict` value for `prev` to see how the graph execution changes depending on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "prev = tf.placeholder(tf.float32)\n",
    "a = (prev < 0,  lambda: prev + 3)\n",
    "b = (prev < 10, lambda: prev * 3)\n",
    "c = (prev < 20, lambda: prev - 3)\n",
    "default = lambda: prev / 3\n",
    "pairs = [a, b, c]\n",
    "out = tf.case(pairs, default)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(out, {prev: 21})\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Depth\n",
    "\n",
    "https://arxiv.org/abs/1603.09382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_depth_conv2d(inputs, filters, kernel_size, keep_prob, padding='same', activation=tf.nn.relu, name=None):\n",
    "    default_name = tf.get_default_graph().unique_name('stochastic_depth_conv')\n",
    "    with tf.variable_scope(name, default_name):\n",
    "        def full_layer():\n",
    "            return tf.layers.conv2d(inputs, filters, kernel_size, padding=padding, activation=activation, name='conv')\n",
    "        def skip_layer():\n",
    "            if inputs.get_shape().as_list()[-1] != filters:\n",
    "                return tf.layers.conv2d(inputs, filters, [1, 1], padding=padding, activation=activation, name='skip')\n",
    "            else:\n",
    "                return inputs\n",
    "        pred = tf.random_uniform([]) < keep_prob\n",
    "        return tf.cond(pred, full_layer, skip_layer), pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.090465784072876\n",
      "Exporting TensorBoard graph to tbout/stochastic_depth\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 228, 228, 3], name='inputs')\n",
    "keep_prob = tf.placeholder(tf.float32, [], name='keep_prob')\n",
    "conv, _ = stochastic_depth_conv2d(inputs, 32, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 32, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 32, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 64, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 64, [3, 3], keep_prob)\n",
    "conv, _ = stochastic_depth_conv2d(conv, 64, [3, 3], keep_prob)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {\n",
    "        inputs: np.random.normal(size=[32, 228, 228, 3]),\n",
    "        keep_prob: 0.5\n",
    "    }\n",
    "    start_t = time.time()\n",
    "    sess.run(conv, feed_dict)\n",
    "    end_t = time.time()\n",
    "    print(end_t - start_t)\n",
    "\n",
    "export_tensorboard_graph('stochastic_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing with TensorBoard\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=tbout/stochastic_depth\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking out gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, [None, 3, 3, 1], name='inputs')\n",
    "keep_prob = tf.placeholder(tf.float32, [], name='keep_prob')\n",
    "conv1, pred1 = stochastic_depth_conv2d(inputs, 3, [3, 3], keep_prob, name='conv1')\n",
    "conv2, pred2 = stochastic_depth_conv2d(conv1, 3, [3, 3], keep_prob, name='conv2')\n",
    "conv3, pred3 = stochastic_depth_conv2d(conv2, 3, [3, 3], keep_prob, name='conv3')\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "var_list = tf.trainable_variables()\n",
    "grads = opt.compute_gradients(conv3, var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True False\n",
      "\n",
      "conv1/conv/kernel\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "\n",
      "conv1/conv/bias\n",
      "[0. 0. 0.]\n",
      "\n",
      "conv1/skip/kernel\n",
      "[ 3.0321338 -4.5531406  2.5450625]\n",
      "\n",
      "conv1/skip/bias\n",
      "[3.5176897 4.589042  2.2859795]\n",
      "\n",
      "conv2/conv/kernel\n",
      "[[[[8.7887740e-01 0.0000000e+00 2.5197589e-03]\n",
      "   [1.9824355e+00 9.7104800e-01 0.0000000e+00]\n",
      "   [6.2200660e-01 0.0000000e+00 1.7833052e-03]]\n",
      "\n",
      "  [[8.8139719e-01 0.0000000e+00 1.2665364e+00]\n",
      "   [3.0903292e+00 2.1192811e+00 0.0000000e+00]\n",
      "   [6.2378991e-01 0.0000000e+00 8.9636391e-01]]\n",
      "\n",
      "  [[1.2690561e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [2.0789416e+00 9.7104800e-01 0.0000000e+00]\n",
      "   [8.9814723e-01 0.0000000e+00 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.3398508e+00 2.5197589e-03 1.0821075e+00]\n",
      "   [1.9824355e+00 1.9824355e+00 9.7104800e-01]\n",
      "   [9.4825065e-01 1.7833052e-03 7.6583838e-01]]\n",
      "\n",
      "  [[3.6884947e+00 2.1454139e+00 0.0000000e+00]\n",
      "   [3.0903292e+00 3.0903292e+00 3.1972237e+00]\n",
      "   [2.6104531e+00 1.5183705e+00 0.0000000e+00]]\n",
      "\n",
      "  [[2.3511636e+00 2.5197589e-03 0.0000000e+00]\n",
      "   [3.1568842e+00 2.0789416e+00 9.7104800e-01]\n",
      "   [1.6639856e+00 1.7833052e-03 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[2.4219584e+00 1.9635047e+00 2.5197589e-03]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [1.7140892e+00 1.3896283e+00 1.7833052e-03]]\n",
      "\n",
      "  [[3.6884949e+00 2.6063874e+00 2.1454139e+00]\n",
      "   [1.0779425e+00 1.0779425e+00 0.0000000e+00]\n",
      "   [2.6104529e+00 1.8446145e+00 1.5183705e+00]]\n",
      "\n",
      "  [[2.3511636e+00 2.3511636e+00 2.5197589e-03]\n",
      "   [1.0779425e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [1.6639856e+00 1.6639856e+00 1.7833052e-03]]]]\n",
      "\n",
      "conv2/conv/bias\n",
      "[8. 5. 3.]\n",
      "\n",
      "conv3/conv/kernel\n",
      "[[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]]\n",
      "\n",
      "conv3/conv/bias\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {\n",
    "        inputs: np.random.normal(size=[1, 3, 3, 1]),\n",
    "        keep_prob: 0.5\n",
    "    }\n",
    "    g, p1, p2, p3 = sess.run([grads, pred1, pred2, pred3], feed_dict)\n",
    "    print(p1, p2, p3)\n",
    "    for var, grad_value in zip(var_list, g):\n",
    "        grad, value = grad_value\n",
    "        print('',var.op.name, grad.squeeze(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Comparison\n",
    "\n",
    "Below, we can see that we only end up running a percentage of the convolutional layers, depending on whether it was dropped or not.\n",
    "\n",
    "Adjust the `keep_prob` parameter inside `feed_dict` in order to play around with different results. The expected runtime of the stocastic depth version of the network is approximately `keep_prob` times the length of the regular network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph...\n",
      "Done.\n",
      "Timing stochastic depth run...\n",
      "Done.\n",
      "1.365527629852295\n"
     ]
    }
   ],
   "source": [
    "# Stochastic version\n",
    "tf.reset_default_graph()\n",
    "print('Building graph...')\n",
    "inputs = tf.placeholder(tf.float32, [None, 228, 228, 3], name='inputs')\n",
    "keep_prob = tf.placeholder(tf.float32, [], name='keep_prob')\n",
    "conv, _ = stochastic_depth_conv2d(inputs, 32, [3, 3], keep_prob)\n",
    "for i in range(10):\n",
    "    conv, _ = stochastic_depth_conv2d(conv, 32, [3, 3], keep_prob)\n",
    "init = tf.global_variables_initializer()\n",
    "print('Done.')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {\n",
    "        inputs: np.random.normal(size=[32, 228, 228, 3]),\n",
    "        # Adjust this parameter to see run speed adjust\n",
    "        keep_prob: 0.5\n",
    "    }\n",
    "    print('Timing stochastic depth run...')\n",
    "    start_t = time.time()\n",
    "    sess.run(conv, feed_dict)\n",
    "    end_t = time.time()\n",
    "    print('Done.')\n",
    "    print(end_t - start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph...\n",
      "Done.\n",
      "Timing standard run...\n",
      "Done.\n",
      "2.229334592819214\n"
     ]
    }
   ],
   "source": [
    "# Standard CNN version\n",
    "tf.reset_default_graph()\n",
    "print('Building graph...')\n",
    "inputs = tf.placeholder(tf.float32, [None, 228, 228, 3], name='inputs')\n",
    "conv = tf.layers.conv2d(inputs, 32, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "for i in range(10):\n",
    "    conv = tf.layers.conv2d(conv, 32, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "init = tf.global_variables_initializer()\n",
    "print('Done.')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {inputs: np.random.normal(size=[32, 228, 228, 3])}\n",
    "    print('Timing standard run...')\n",
    "    start_t = time.time()\n",
    "    sess.run(conv, feed_dict)\n",
    "    end_t = time.time()\n",
    "    print('Done.')\n",
    "    print(end_t - start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow `while_loop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python `for` loop version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.0568227767944336 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Accumulator Variable\n",
    "total = tf.Variable(0.0)\n",
    "# Random inputs to multiply\n",
    "a = tf.random_normal([200, 200])\n",
    "b = tf.random_normal([200, 200])\n",
    "# Calculate value to add to accumulator variable\n",
    "mul = tf.matmul(a, b)\n",
    "mean = tf.reduce_mean(mul)\n",
    "acc = total.assign_add(mean)\n",
    "# Initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    for i in range(2000):\n",
    "        final_total = sess.run(acc)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `while_loop` version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.3016061782836914 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Accumulator Variable\n",
    "total = tf.Variable(0.0)\n",
    "i = tf.constant(0)\n",
    "# Define the loop body\n",
    "def body(i, _):\n",
    "    a = tf.random_normal([200, 200])\n",
    "    b = tf.random_normal([200, 200])\n",
    "    mul = tf.matmul(a, b)\n",
    "    mean = tf.reduce_mean(mul)\n",
    "    acc = total.assign_add(mean)\n",
    "    return i+1, acc\n",
    "# Define the loop condition\n",
    "def condition(i, _):\n",
    "    return tf.less(i, 2000)\n",
    "# Create the while_loop\n",
    "out = tf.while_loop(condition, body, [i, total])\n",
    "# Initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_t = time.time()\n",
    "    final_i, final_total = sess.run(out)\n",
    "    end_t = time.time()\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condensed version of the above\n",
    "\n",
    "This is the same graph from above, but condensed with by using a `lambda` and some TensorFlow sugar. We'll also export it so that we can explore it in `tensorboard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting TensorBoard graph to tbout/while_loop\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Accumulator Variable\n",
    "total = tf.Variable(0.0)\n",
    "# Define the loop body\n",
    "def body(i, _):\n",
    "    a = tf.random_normal([200, 200])\n",
    "    b = tf.random_normal([200, 200])\n",
    "    mul = tf.matmul(a, b)\n",
    "    mean = tf.reduce_mean(mul)\n",
    "    acc = total.assign_add(mean)\n",
    "    return i+1, acc\n",
    "# Create the while_loop\n",
    "out = tf.while_loop(lambda i, _: i < 200, body, [0, total])\n",
    "# Initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "export_tensorboard_graph('while_loop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing with TensorBoard\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=tbout/while_loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What about \"unrolling\" the loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation time: 8.232242107391357 seconds\n",
      "Time elapsed: 3.455287218093872 seconds\n"
     ]
    }
   ],
   "source": [
    "# Unrolled version\n",
    "tf.reset_default_graph()\n",
    "graph_start_time = time.time()\n",
    "# Random inputs to multiply\n",
    "a = tf.random_normal([200, 200])\n",
    "for i in range(2000):\n",
    "    a = tf.matmul(a, tf.random_normal([200, 200]))\n",
    "graph_creation_time = time.time() - graph_start_time\n",
    "with tf.Session() as sess:\n",
    "    start_t = time.time()\n",
    "    final_total = sess.run(a)\n",
    "    end_t = time.time()\n",
    "    print('Graph creation time: {} seconds'.format(graph_creation_time))\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creation time: 0.020896196365356445 seconds\n",
      "Time elapsed: 0.43869447708129883 seconds\n"
     ]
    }
   ],
   "source": [
    "# tf.while_loop version\n",
    "tf.reset_default_graph()\n",
    "graph_start_time = time.time()\n",
    "# Define the loop body\n",
    "def body(i, a):\n",
    "    with tf.name_scope('body'):\n",
    "        return i+1, tf.matmul(a, tf.random_normal([200, 200]))\n",
    "# Create the while_loop\n",
    "out = tf.while_loop(lambda i, _: i < 2000, body, [0, tf.random_normal([200, 200])])\n",
    "graph_creation_time = time.time() - graph_start_time\n",
    "with tf.Session() as sess:\n",
    "    start_t = time.time()\n",
    "    final_i, final_total = sess.run(out)\n",
    "    end_t = time.time()\n",
    "    print('Graph creation time: {} seconds'.format(graph_creation_time))\n",
    "    print('Time elapsed: {} seconds'.format(end_t - start_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN\n",
    "\n",
    "`tf.dynamic_rnn` is implemented with a `tf.while_loop`. The actual implementation is much more robust (uses `RNNCell`, saves state at each step, accepts per-input lengths, etc), but this illustrates a basic example.\n",
    "\n",
    "If you want to save states from each time step, you'll want to use a `TensorArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.while_loop version\n",
    "tf.reset_default_graph()\n",
    "x_input = tf.placeholder(tf.float32, [None, 20, 200])\n",
    "length_input = tf.placeholder(tf.int32, [])\n",
    "# Define the condition\n",
    "def cond(x, state, i, length):\n",
    "    return i < length\n",
    "# Define the loop body\n",
    "def body(x, state, i, length):\n",
    "    with tf.variable_scope('body', initializer=tf.random_normal_initializer()):\n",
    "        x_reshape = tf.reshape(x, [20, -1, 200])\n",
    "        # Get the input at timestep i\n",
    "        x_slice = tf.gather(x_reshape, i)\n",
    "        w = tf.get_variable('weight', [200, 200])\n",
    "        z = tf.matmul(x_slice + state, w)\n",
    "        a = tf.nn.tanh(z)\n",
    "        return x, a, i+1, length \n",
    "# Create the while_loop\n",
    "# Create zeros with dynamic shape based on inputs\n",
    "state_shape = tf.stack([tf.shape(x_input)[0], 200])\n",
    "start_state = tf.zeros(state_shape)\n",
    "# Create while_loop\n",
    "out = tf.while_loop(cond, body, (x_input, start_state, 0, length_input))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012059688568115234\n",
      "[[ 0.9999997  -1.          1.         ...  1.         -0.994401\n",
      "   1.        ]\n",
      " [-0.9945827  -0.9999559   0.9984477  ... -1.         -0.99999994\n",
      "  -0.9357829 ]\n",
      " [-1.         -1.          1.         ...  1.         -1.\n",
      "   1.        ]\n",
      " ...\n",
      " [-1.          1.          1.         ... -0.99112177  1.\n",
      "   0.99999833]\n",
      " [-0.99987483  1.          1.         ...  1.          1.\n",
      "  -1.        ]\n",
      " [ 0.99998266 -1.          1.         ...  1.          1.\n",
      "   0.9474561 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    feed_dict = {\n",
    "        x_input: np.random.normal(size=[10, 20, 200]),\n",
    "        length_input: 20\n",
    "    }\n",
    "    start_t = time.time()\n",
    "    final_x, final_state, final_i, final_length = sess.run(out, feed_dict)\n",
    "    end_t = time.time()\n",
    "    print(end_t - start_t)\n",
    "    print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
