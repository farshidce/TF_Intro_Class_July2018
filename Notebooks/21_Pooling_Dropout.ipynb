{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Operations\n",
    "\n",
    "* The role of pooling layers is to reduce the dimensionality of the input. \n",
    "* Pooling layers are typically put right after convolution layers. \n",
    "* Reducing the dimensionality of the input both reduces the number of parameters and therefore the complexity of the network and in turns reduces overfitting.\n",
    "* Obviously, we may lose some information as well, but the hope is that we retain most of the key information relative to our task.\n",
    "* The pooling layer operates over every depth slice and does nothing to change the depth of the input. However, the output height and width are reduced through sampling areas of the image.\n",
    "* The most common type of pooling is max pooling. \n",
    "* Max pooling takes only the maximum pixel value from a region of pixels. \n",
    "* So for instance for a max pooling with filter size of 2x2 with a stride of 2 would reduce a 8x8 image to a 2x2 image. \n",
    "* Typically the stride of the filter is just the filter size. \n",
    "* In the image below each color of the image is a region that the pooling considers independently of the other regions.\n",
    "* In theory, Max pooling actually makes the network a more powerful feature detector as only the areas with maximum response to the convolution operator are kept. \n",
    "* This preserves the most important features while throwing out the less important features.\n",
    "* Pooling can be viewed as a type of down sampling. \n",
    "* For max pooling backpropagation just has to know which pixel from each region had the highest value in the forward pass so that the gradient is only routed through that pixel. \n",
    "* Besides that everything else remains the same as for convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../pics/maxpool_1.jpeg' style=\"width: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../pics/relufamily.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "* Dropout is mostly a technique for regularization.\n",
    "* Dropout introduces noise into the neural network to force it to learn to generalize well enough to deal with noise\n",
    "* The noise that we introduce is essentially a matrix of zeros and ones whose purpose is to temporarily \"zero out\" some of the neurons in our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../pics/dropout_1.png' style=\"width: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../pics/dropout_test_time.png' style=\"width: 400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
