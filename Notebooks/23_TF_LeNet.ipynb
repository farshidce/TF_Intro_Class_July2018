{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet Architecture\n",
    "<img src='../pics/lenet0.png'>\n",
    "<img src='../pics/lenet6.png' width='1000px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet First Two Layers\n",
    "<img src='../pics/lenet_first_two_convs.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the above diagram, you can see how the input image is processed in the first convolutional layer using the filter weights. \n",
    "* This results in 32 new images, one for each filter in the convolutional layer. \n",
    "* The images are also down-sampled with the pooling operation, so the image resolution is decreased from 28×28 to 14×14. \n",
    "* These 32 smaller images are then processed in the second convolutional layer. \n",
    "* We need filter weights again for each of these 32 images and we need filter weights for each output channel of this layer. \n",
    "* The images are again down-sampled with a pooling operation, so that the image resolution is decreased from 14×14 to 7×7. \n",
    "* The total number of features for this convolutional layer is 64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet Last Three Convolutional Layers\n",
    "<img src='../pics/lenet_last_three.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The 64 resulting images are filtered again by a (3×3) third convolutional layer. No pooling operation is applied to this layer. \n",
    "* The output of the third convolutional layer is 128 7×7-pixel images. \n",
    "* These images are then flattened to become a single vector, of length 4×4×128 = 2048, which is used as input to a fully connected layer.\n",
    "* The output layer has 625 neurons as input (that is, the output of the fully connected layer), and 10 neurons as output, since there are 10 classes of images that we are deciding between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet Architecture Again\n",
    "<img src='../pics/lenet3.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, w, w2, w3, w4, w_o, p_keep_conv, p_keep_hidden):\n",
    "\n",
    "    conv1 = tf.nn.conv2d(X, w,\\\n",
    "                         strides=[1, 1, 1, 1],\\\n",
    "                         padding='SAME')\n",
    "\n",
    "    conv1_a = tf.nn.relu(conv1)\n",
    "    conv1 = tf.nn.max_pool(conv1_a, ksize=[1, 2, 2, 1]\\\n",
    "                        ,strides=[1, 2, 2, 1],\\\n",
    "                        padding='SAME')\n",
    "    conv1 = tf.nn.dropout(conv1, p_keep_conv)\n",
    "\n",
    "    conv2 = tf.nn.conv2d(conv1, w2,\\\n",
    "                         strides=[1, 1, 1, 1],\\\n",
    "                         padding='SAME')\n",
    "    conv2_a = tf.nn.relu(conv2)\n",
    "    conv2 = tf.nn.max_pool(conv2_a, ksize=[1, 2, 2, 1],\\\n",
    "                        strides=[1, 2, 2, 1],\\\n",
    "                        padding='SAME')\n",
    "    conv2 = tf.nn.dropout(conv2, p_keep_conv)\n",
    "\n",
    "    conv3=tf.nn.conv2d(conv2, w3,\\\n",
    "                       strides=[1, 1, 1, 1]\\\n",
    "                       ,padding='SAME')\n",
    "\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "\n",
    "    FC_layer = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1],\\\n",
    "                        strides=[1, 2, 2, 1],\\\n",
    "                        padding='SAME')\n",
    "    \n",
    "    FC_layer = tf.reshape(FC_layer,\\\n",
    "                          [-1, w4.get_shape().as_list()[0]])    \n",
    "    FC_layer = tf.nn.dropout(FC_layer, p_keep_conv)\n",
    "\n",
    "\n",
    "    output_layer = tf.nn.relu(tf.matmul(FC_layer, w4))\n",
    "    output_layer = tf.nn.dropout(output_layer, p_keep_hidden)\n",
    "\n",
    "    result = tf.matmul(output_layer, w_o)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from mnist_loader import read_data_sets\n",
    "mnist = read_data_sets('../data/mnist', one_hot=True)\n",
    "\n",
    "trX, trY, teX, teY = mnist.train.images,\\\n",
    "                     mnist.train.labels, \\\n",
    "                     mnist.test.images, \\\n",
    "                     mnist.test.labels\n",
    "\n",
    "batch_size = 128\n",
    "test_size = 256\n",
    "img_size = 28\n",
    "num_classes = 10\n",
    "            \n",
    "trX = trX.reshape(-1, img_size, img_size, 1)  # 28x28x1 input img\n",
    "teX = teX.reshape(-1, img_size, img_size, 1)  # 28x28x1 input img\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, img_size, img_size, 1])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# The init_weights function builds new variables in the shape provided \n",
    "# and initializes the network's weights with random values:\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "# Each neuron of the first convolutional layer is convoluted to \n",
    "# a small subset of the input tensor, with the dimensions 3×3×1. \n",
    "# The value 32 is just the number of feature maps we are considering \n",
    "# for this first layer. The weight, w, is then defined:\n",
    "w = init_weights([3, 3, 1, 32])       # 3x3x1 conv, 32 outputs\n",
    "\n",
    "\n",
    "w2 = init_weights([3, 3, 32, 64])     # 3x3x32 conv, 64 outputs\n",
    "w3 = init_weights([3, 3, 64, 128])    # 3x3x32 conv, 128 outputs\n",
    "w4 = init_weights([128 * 4 * 4, 625]) # FC 128 * 4 * 4 inputs, 625 outputs\n",
    "w_o = init_weights([625, num_classes])# FC 625 inputs, 10 outputs (labels)\n",
    "\n",
    "p_keep_conv = tf.placeholder(\"float\")\n",
    "p_keep_hidden = tf.placeholder(\"float\")\n",
    "py_x = model(X, w, w2, w3, w4, w_o, p_keep_conv, p_keep_hidden)\n",
    "\n",
    "Y_ = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y,logits=py_x)\n",
    "\n",
    "cost = tf.reduce_mean(Y_)\n",
    "optimizer  = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Accuracy:  0.984375\n",
      "Epoch:  3  Accuracy:  0.98828125\n",
      "Epoch:  5  Accuracy:  0.98046875\n",
      "Epoch:  7  Accuracy:  0.99609375\n",
      "Epoch:  9  Accuracy:  0.9921875\n",
      "Epoch:  11  Accuracy:  0.99609375\n",
      "Epoch:  13  Accuracy:  0.98828125\n",
      "Epoch:  15  Accuracy:  0.9921875\n",
      "Epoch:  17  Accuracy:  0.9921875\n",
      "Epoch:  19  Accuracy:  0.9921875\n"
     ]
    }
   ],
   "source": [
    "print_every = 2\n",
    "num_epochs = 20\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True))\n",
    "#with tf.Session() as sess:\n",
    "with sess.as_default():\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(num_epochs):\n",
    "        training_batch = \\\n",
    "                       zip(range(0, len(trX), \\\n",
    "                                 batch_size),\n",
    "                             range(batch_size, \\\n",
    "                                   len(trX)+1, \\\n",
    "                                   batch_size))\n",
    "        for start, end in training_batch:\n",
    "            sess.run(optimizer , feed_dict={X: trX[start:end],\\\n",
    "                                          Y: trY[start:end],\\\n",
    "                                          p_keep_conv: 0.8,\\\n",
    "                                          p_keep_hidden: 0.5})\n",
    "\n",
    "        test_indices = np.arange(len(teX)) # Get A Test Batch\n",
    "        np.random.shuffle(test_indices)\n",
    "        test_indices = test_indices[0:test_size]\n",
    "\n",
    "        if (i+1) % print_every == 0:\n",
    "            ACCURACY = np.mean(np.argmax(teY[test_indices], axis=1) ==\\\n",
    "                             sess.run(predict_op,\\\n",
    "                              feed_dict={X: teX[test_indices],\\\n",
    "                                         Y: teY[test_indices], \\\n",
    "                                         p_keep_conv: 1.0,\\\n",
    "                                         p_keep_hidden: 1.0}))\n",
    "\n",
    "            print(\"Epoch: \",i,\" Accuracy: \",ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
