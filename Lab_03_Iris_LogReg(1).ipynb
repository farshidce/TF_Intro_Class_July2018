{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# Load the data\n",
    "# iris.data = [(Sepal Length, Sepal Width, Petal Length, Petal Width)]\n",
    "irisdataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = irisdataset.data\n",
    "y_vals = irisdataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vals[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>CategoryId</th>\n",
       "      <th>IdLabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>Versicolour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>Versicolour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>Versicolour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  CategoryId  \\\n",
       "55             5.7           2.8            4.5           1.3           1   \n",
       "83             6.0           2.7            5.1           1.6           1   \n",
       "148            6.2           3.4            5.4           2.3           2   \n",
       "111            6.4           2.7            5.3           1.9           2   \n",
       "23             5.1           3.3            1.7           0.5           0   \n",
       "42             4.4           3.2            1.3           0.2           0   \n",
       "92             5.8           2.6            4.0           1.2           1   \n",
       "15             5.7           4.4            1.5           0.4           0   \n",
       "\n",
       "        IdLabels  \n",
       "55   Versicolour  \n",
       "83   Versicolour  \n",
       "148    Virginica  \n",
       "111    Virginica  \n",
       "23        Setosa  \n",
       "42        Setosa  \n",
       "92   Versicolour  \n",
       "15        Setosa  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.DataFrame(x_vals,columns=[\"SepalLengthCm\", \"SepalWidthCm\" , \"PetalLengthCm\", \"PetalWidthCm\"])\n",
    "iris[\"CategoryId\"] = y_vals\n",
    "names={0:\"Setosa\",1:\"Versicolour\",2:\"Virginica\"}\n",
    "iris[\"IdLabels\"] = iris[\"CategoryId\"].replace(names,inplace=False)\n",
    "iris.sample(8,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 6)\n",
      "Versicolour    50\n",
      "Setosa         50\n",
      "Virginica      50\n",
      "Name: IdLabels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(iris.shape)\n",
    "print(iris[\"IdLabels\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick Two Categories for binary classification\n",
    "* There are 50 from each category, and the dataset is already sorted, so we keep the first 100 rows of data\n",
    "* The Setosa iris species is linearly separable from the other two, but Virginica and Versicolor are not linearly separable from each other, so we'll compare Setosa vs Versicolour and then Versicolour vs Virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f591e694b70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note there are 50 from each category in the dataset\n",
    "plt.scatter(iris[:50].SepalLengthCm, iris[:50].SepalWidthCm, label='Iris-setosa')\n",
    "plt.scatter(iris[51:].SepalLengthCm, iris[51:].SepalWidthCm, label='Iris-versicolo')\n",
    "plt.xlabel('SepalLength')\n",
    "plt.ylabel('SepalWidth')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X and y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop(labels=['CategoryId', 'IdLabels'], axis=1).values\n",
    "y = iris[\"CategoryId\"]\n",
    "\n",
    "# Set random seed for numpy and tensorflow for reproducible results\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and test sets\n",
    "* We will be randomizing the data with `train_index` since the dataset is categegorized\n",
    "* In `np.random.choice` we set `replace=False` to avoid double-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percent of our data we want to use for training data\n",
    "train_pct = 0.8\n",
    "\n",
    "train_index = np.random.choice(len(X), round(len(X) * train_pct), replace=False)\n",
    "test_index = np.array(list(set(range(len(X))) - set(train_index)))\n",
    "train_X = X[train_index]\n",
    "train_y = y[train_index]\n",
    "test_X = X[test_index]\n",
    "test_y = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_X),type(test_X),type(train_y),type(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data\n",
    "* For logistic regression, normalization isn't strictly required\n",
    "* The main goal of normalizing features is to help convergence during optimization.\n",
    "* Remember that in logistic regression your coefficients indicate the effect of a one-unit change in your predictor variable on the log odds of 'success'. \n",
    "* The effect of transforming a variable (such as by standardizing or normalizing) is to change what we are calling a 'unit' in the context of our model. \n",
    "* The raw x data varies across some number of units in its original form. \n",
    "* After you normalize, your data ranges from **`0` to `1`**. \n",
    "* So now a change of one unit means going from the lowest valued observation to the highest valued observation. \n",
    "* The amount of increase in the log odds of success has not changed. \n",
    "* But we **DO** need to normalize for other machine learning algorithms, such as LASSO or ridge regression (because they put constraints on the size of the coefficients associated to each variable).\n",
    "* As we will see later, when we talk more extensively about batch normalization, this can be very important for neural networks as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to normalize the data\n",
    "def min_max_normalized(data):\n",
    "    col_max = np.max(data, axis=0)\n",
    "    col_min = np.min(data, axis=0)\n",
    "    return np.divide(data - col_min, col_max - col_min)\n",
    "\n",
    "# Normalized processing, must be placed after the data set segmentation, \n",
    "# otherwise the test set will be affected by the training set\n",
    "train_X = min_max_normalized(train_X)\n",
    "test_X = min_max_normalized(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "* Begin building the model framework\n",
    "* Declare the variables that need to be learned (i.e. weights and biases)\n",
    "* Make sure to give your variables the right shape - you will be able to figure this out from how many features there are\n",
    "* There are 4 features here, A's dimension is (4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "A = tf.Variable(tf.random_normal(shape=[4,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the placeholders for our data\n",
    "* You will need placeholders for the features and labels.\n",
    "* Be sure to declare a data type, and the appropriate shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "x_data = tf.placeholder(shape=[None, 4], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the operations for the model that you need to learn\n",
    "* In this case we are doing logistic regression, so remember that the formula is:\n",
    "\n",
    "$$\\Large{ \\textbf{y} = \\sigma(\\textbf{A}\\times \\textbf{x} + \\textbf{b})}$$\n",
    "\n",
    "* Where $\\sigma$ is the sigmoid function\n",
    "* Keep in mind that we will be doing the sigmoid operation as part of our loss function, so we don't need to do it twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "model_output = tf.add(tf.matmul(x_data, A), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare a loss function\n",
    "* Use the sigmoid cross entropy loss function `tf.nn.sigmoid_cross_entropy_with_logits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the learning rate,  batch size, and the number of iterations you will run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "batch_size = 30\n",
    "iter_num = 2400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the optimizer\n",
    "* Use `tf.train.GradientDescentOptimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your training step\n",
    "* This is the **goal** of the learning/optimization process - i.e. what are we doing with loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default threshold is 0.5, rounded off directly\n",
    "prediction = tf.round(tf.sigmoid(model_output))\n",
    "# Bool into float32 type\n",
    "correct = tf.cast(tf.equal(prediction, y_target), dtype=tf.float32)\n",
    "# Average\n",
    "accuracy = tf.reduce_mean(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "You will need to do the following:\n",
    "1. Set up a training session\n",
    "2. Initialize variables\n",
    "3. Evaluate your training step, accuracy, and loss at each epoch.\n",
    "4. Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_X),type(test_X),type(train_y),type(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4) (80,)\n"
     ]
    }
   ],
   "source": [
    "train_y=np.array(train_y)\n",
    "print(train_X.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(train_y,size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training model\n",
    "# Define the variable that stores the result\n",
    "loss_trace = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "# Set up a session and initialize variables\n",
    "### YOUR CODE HERE\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# training model\n",
    "for epoch in range(iter_num):\n",
    "    # Generate random batch index\n",
    "    batch_index = np.random.choice(len(train_X), size=batch_size)\n",
    "    batch_train_X = train_X[batch_index]\n",
    "    batch_train_y = np.transpose([train_y[batch_index]])\n",
    "    \n",
    "    # Evaluate your training step, accuracy, and loss at each epoch.\n",
    "    ### YOUR CODE HERE\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: batch_train_X, y_target: batch_train_y})\n",
    "    temp_train_acc = sess.run(accuracy, feed_dict={x_data: train_X, y_target: np.transpose([train_y])})\n",
    "    temp_test_acc = sess.run(accuracy, feed_dict={x_data: test_X, y_target: np.transpose([test_y])})\n",
    "\n",
    "    #temp_loss = sess.run(loss, feed_dict={x_data: batch_train_X, y_target: batch_train_y})\n",
    "    loss_trace.append(temp_loss)\n",
    "    #temp_train_acc = sess.run(accuracy, feed_dict={x_data: train_X, y_target: np.transpose([train_y])})\n",
    "    #temp_test_acc = sess.run(accuracy, feed_dict={x_data: test_X, y_target: np.transpose([test_y])})\n",
    "\n",
    "    # store the results\n",
    "    ### YOUR CODE HERE\n",
    "    train_acc.append(temp_train_acc)\n",
    "    test_acc.append(temp_test_acc)\n",
    "\n",
    "    \n",
    "    # output\n",
    "#     if (epoch + 1) % 300 == 0:\n",
    "#         print('epoch: {:4d} loss: {:5f} train_acc: {:5f} test_acc: {:5f}'.format(epoch + 1, temp_loss,\n",
    "#                                                                           temp_train_acc, temp_test_acc))\n",
    "        \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_trace[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2-D, but have shapes (2400,) and (2400, 30, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b99c36abfff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross Entropy Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n\u001b[0;32m--> 245\u001b[0;31m                              \"shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (2400,) and (2400, 30, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_trace)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "plt.plot(train_acc, 'b-', label='train accuracy')\n",
    "plt.plot(test_acc, 'k-', label='test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
