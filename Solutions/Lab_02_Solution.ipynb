{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Delete previous tensorboard graph\n",
    "if os.path.exists('./tmp/lab2'):\n",
    "    !rm /tmp/lab2/*.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Namescopes, Graphs, and Matrix Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise -  Create and run a computational graph that does the following:\n",
    "* Under the name scope \"Inputs\":\n",
    "    * Create 3 different 10x10 matrices - `A`, `B`, and `C` each of which are filled with random numbers from a normal gaussian distribution and that have a mean of 1, 3, and 5 respectively.\n",
    "$$$$    \n",
    "* Under the name scope \"Concats\":\n",
    "    * Create matrix `D` by concatenating `A` and `B` along the column dimension\n",
    "    * Create matrix `E` by concatenating `B` and `C` along the column dimension\n",
    "$$$$\n",
    "* Under the name scope \"Split\":\n",
    "    * Create matrices `F` and `G` by splitting matrix B along the row dimension\n",
    "$$$$\n",
    "* Create matrix `H` which should be the column-wise mean of `B`\n",
    "* Matrix I should be vector `B` multiplied using broadcasting over `H`\n",
    "$$$$\n",
    "* Print the means of D, E, F and I\n",
    "* Print the shape of E, F, G and H\n",
    "$$$$\n",
    "* For extra credit, add additional names that will provide even further clarification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Inputs\"):\n",
    "    A = tf.random_normal((10,10),mean=1,name=\"A\")\n",
    "    B = tf.random_normal((10,10),mean=3,name=\"B\")\n",
    "    C = tf.random_normal((10,10),mean=5,name=\"C\")\n",
    "with tf.name_scope(\"Concats\"):\n",
    "    D = tf.concat([A, B],axis=1,name=\"Concat_D\")\n",
    "    E = tf.concat([B, C],axis=1,name=\"Concat_E\")\n",
    "with tf.name_scope(\"Split\"):\n",
    "    F, G = tf.split(axis=0, num_or_size_splits=2, value=B)\n",
    "\n",
    "H = tf.reduce_mean(B,axis=1,name=\"H\")\n",
    "I = tf.multiply(H,C,name=\"I\")\n",
    "\n",
    "D_avg = tf.reduce_mean(D,name=\"D_avg\")\n",
    "E_avg = tf.reduce_mean(E,name=\"E_avg\")\n",
    "F_avg = tf.reduce_mean(F,name=\"F_avg\")\n",
    "I_avg = tf.reduce_mean(I,name=\"I_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"summaries\"):\n",
    "    tf.summary.scalar(\"D_avg\", D_avg)\n",
    "    tf.summary.scalar(\"E_avg\", E_avg)\n",
    "    tf.summary.scalar(\"I_avg\", I_avg)\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter('/tmp/lab2', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20) (5, 10) (5, 10) (10,)\n"
     ]
    }
   ],
   "source": [
    "print(E.shape,F.shape,G.shape,H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0045393, 4.0301485, 3.114893, 15.102457]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run([merged,D_avg,E_avg,I])\n",
    "    print(sess.run([D_avg, E_avg, F_avg, I_avg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Inputs/A/shape' type=Const>,\n",
       " <tf.Operation 'Inputs/A/mean' type=Const>,\n",
       " <tf.Operation 'Inputs/A/stddev' type=Const>,\n",
       " <tf.Operation 'Inputs/A/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'Inputs/A/mul' type=Mul>,\n",
       " <tf.Operation 'Inputs/A' type=Add>,\n",
       " <tf.Operation 'Inputs/B/shape' type=Const>,\n",
       " <tf.Operation 'Inputs/B/mean' type=Const>,\n",
       " <tf.Operation 'Inputs/B/stddev' type=Const>,\n",
       " <tf.Operation 'Inputs/B/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'Inputs/B/mul' type=Mul>,\n",
       " <tf.Operation 'Inputs/B' type=Add>,\n",
       " <tf.Operation 'Inputs/C/shape' type=Const>,\n",
       " <tf.Operation 'Inputs/C/mean' type=Const>,\n",
       " <tf.Operation 'Inputs/C/stddev' type=Const>,\n",
       " <tf.Operation 'Inputs/C/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'Inputs/C/mul' type=Mul>,\n",
       " <tf.Operation 'Inputs/C' type=Add>,\n",
       " <tf.Operation 'Concats/Concat_D/axis' type=Const>,\n",
       " <tf.Operation 'Concats/Concat_D' type=ConcatV2>,\n",
       " <tf.Operation 'Concats/Concat_E/axis' type=Const>,\n",
       " <tf.Operation 'Concats/Concat_E' type=ConcatV2>,\n",
       " <tf.Operation 'Split/Const' type=Const>,\n",
       " <tf.Operation 'Split/split/split_dim' type=Const>,\n",
       " <tf.Operation 'Split/split' type=Split>,\n",
       " <tf.Operation 'H/reduction_indices' type=Const>,\n",
       " <tf.Operation 'H' type=Mean>,\n",
       " <tf.Operation 'I' type=Mul>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'D_avg' type=Mean>,\n",
       " <tf.Operation 'Const_1' type=Const>,\n",
       " <tf.Operation 'E_avg' type=Mean>,\n",
       " <tf.Operation 'Const_2' type=Const>,\n",
       " <tf.Operation 'F_avg' type=Mean>,\n",
       " <tf.Operation 'Const_3' type=Const>,\n",
       " <tf.Operation 'I_avg' type=Mean>,\n",
       " <tf.Operation 'Inputs_1/A/shape' type=Const>,\n",
       " <tf.Operation 'Inputs_1/A/mean' type=Const>,\n",
       " <tf.Operation 'Inputs_1/A/stddev' type=Const>,\n",
       " <tf.Operation 'Inputs_1/A/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'Inputs_1/A/mul' type=Mul>,\n",
       " <tf.Operation 'Inputs_1/A' type=Add>,\n",
       " <tf.Operation 'Inputs_1/B/shape' type=Const>,\n",
       " <tf.Operation 'Inputs_1/B/mean' type=Const>,\n",
       " <tf.Operation 'Inputs_1/B/stddev' type=Const>,\n",
       " <tf.Operation 'Inputs_1/B/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'Inputs_1/B/mul' type=Mul>,\n",
       " <tf.Operation 'Inputs_1/B' type=Add>,\n",
       " <tf.Operation 'Inputs_1/C/shape' type=Const>,\n",
       " <tf.Operation 'Inputs_1/C/mean' type=Const>,\n",
       " <tf.Operation 'Inputs_1/C/stddev' type=Const>,\n",
       " <tf.Operation 'Inputs_1/C/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'Inputs_1/C/mul' type=Mul>,\n",
       " <tf.Operation 'Inputs_1/C' type=Add>,\n",
       " <tf.Operation 'Concats_1/Concat_D/axis' type=Const>,\n",
       " <tf.Operation 'Concats_1/Concat_D' type=ConcatV2>,\n",
       " <tf.Operation 'Concats_1/Concat_E/axis' type=Const>,\n",
       " <tf.Operation 'Concats_1/Concat_E' type=ConcatV2>,\n",
       " <tf.Operation 'Split_1/Const' type=Const>,\n",
       " <tf.Operation 'Split_1/split/split_dim' type=Const>,\n",
       " <tf.Operation 'Split_1/split' type=Split>,\n",
       " <tf.Operation 'H_1/reduction_indices' type=Const>,\n",
       " <tf.Operation 'H_1' type=Mean>,\n",
       " <tf.Operation 'I_1' type=Mul>,\n",
       " <tf.Operation 'Const_4' type=Const>,\n",
       " <tf.Operation 'D_avg_1' type=Mean>,\n",
       " <tf.Operation 'Const_5' type=Const>,\n",
       " <tf.Operation 'E_avg_1' type=Mean>,\n",
       " <tf.Operation 'Const_6' type=Const>,\n",
       " <tf.Operation 'F_avg_1' type=Mean>,\n",
       " <tf.Operation 'Const_7' type=Const>,\n",
       " <tf.Operation 'I_avg_1' type=Mean>,\n",
       " <tf.Operation 'summaries/D_avg/tags' type=Const>,\n",
       " <tf.Operation 'summaries/D_avg' type=ScalarSummary>,\n",
       " <tf.Operation 'summaries/E_avg/tags' type=Const>,\n",
       " <tf.Operation 'summaries/E_avg' type=ScalarSummary>,\n",
       " <tf.Operation 'summaries/I_avg/tags' type=Const>,\n",
       " <tf.Operation 'summaries/I_avg' type=ScalarSummary>,\n",
       " <tf.Operation 'summaries/Merge/MergeSummary' type=MergeSummary>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-06-18 22:26:32.090383: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "TensorBoard 1.8.0 at http://d2086dcc03df:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=/tmp/lab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
